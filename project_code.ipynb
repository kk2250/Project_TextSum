{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import gensim\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/Jassandip/Desktop/Byte/Projects/text_summerizer/tensor_flow/is-karthikbmk-master/src'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(\"open /Users/Jassandip/Desktop/Byte/Projects/text_summerizer/tensor_flow/is-karthikbmk-master/src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = glob.glob('../data/DUC2001/Summaries/*.txt')\n",
    "string = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(len(all_files)):\n",
    "    with open(all_files[_],'rt') as file:\n",
    "        txt_file = file.read()\n",
    "        for word in txt_file:\n",
    "            string += word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data1/sample{}.txt'.format(_),'w') as file1:\n",
    "    file1.write('{}'.format(string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files1 = glob.glob('data1/*.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_input(input_file):\n",
    "    with open(input_file,'rt') as f:\n",
    "        for line in f:\n",
    "            yield gensim.utils.simple_preprocess(line)\n",
    "\n",
    "documents1 = []\n",
    "documents2 = []\n",
    "documents3 = []\n",
    "\n",
    "for _ in range(len(all_files1)):\n",
    "    documents = list(read_input('{}'.format(all_files1[_])))\n",
    "    for __ in range(len(documents)):\n",
    "        for ___ in range(len(documents[__])):\n",
    "            documents1.append(documents[__][___])\n",
    "\n",
    "    for __ in range(len(documents1)):\n",
    "        if documents1[__] == 'introduction':\n",
    "            documents2.append(documents1[__+1:])\n",
    "\n",
    "    documents3.append(documents2)\n",
    "\n",
    "with open('list_word.txt','w') as file2:\n",
    "    file2.write('{}'.format(documents3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renames the files, use it make .txt files\n",
    "# for filename in os.listdir(data_root_dir): \n",
    "#         src = data_root_dir + filename \n",
    "#         dst = src + '.txt'\n",
    "          \n",
    "#         # rename() function will \n",
    "#         # rename all the files \n",
    "#         os.rename(src, dst) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor_flow",
   "language": "python",
   "name": "tensor_flow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
